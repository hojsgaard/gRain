%\VignetteIndexEntry{grain-intro}
%\VignetteDepends{gRbase}
%\VignetteKeyword{Bayesian networks}
%\VignetteKeyword{Graphical Models}
%\VignetteKeyword{Probabilistic networks}
%\VignetteEngine{knitr::knitr} 

\documentclass[10pt]{article}\usepackage[]{graphicx}\usepackage[]{xcolor}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usepackage{boxedminipage,color,a4wide,url}
\usepackage[utf8]{inputenc}

\usepackage[authoryear,round]{natbib}
\bibliographystyle{plainnat}



\usepackage{etoolbox} 
\makeatletter 
\preto{\@verbatim}{\topsep=0pt \partopsep=-25pt } 
\makeatother

\usepackage{alltt}
\AtBeginEnvironment{alltt}{\setlength{\topsep}{-25pt}}



\def\pkg#1{{\bf #1}}
\def\grbn{{\bf gRain}}
\def\grain{\texttt{grain}}
\def\code#1{{\texttt{#1}}}
\def\R{\texttt{R}}
\def\bn{Bayesian network}



\author{S{\o}ren H{\o}jsgaard\\Aalborg University, Denmark}
\title{Bayesian networks in R with the \pkg{gRain} package}
\date{\pkg{gRain} version 1.3.12 as of 2022-11-15}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}
\maketitle
\tableofcontents
\parindent0pt\parskip5pt

\section{Introduction}

The \grbn\ package implements Bayesian Networks (hereafter often
abbreviated BNs). The name \grbn\ is an acronym for [gra]phical
[i]ndependence [n]etworks. The main reference for \grbn\  is
\cite{hoj:12}, see also

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{citation}\hlstd{(}\hlstr{"gRain"}\hlstd{)}
\end{alltt}
\begin{verbatim}
## 
## To cite gRain in publications use:
## 
##   Søren Højsgaard (2012). Graphical Independence Networks with the gRain
##   Package for R. Journal of Statistical Software, 46(10), 1-26. URL
##   https://www.jstatsoft.org/v46/i10/
## 
## A BibTeX entry for LaTeX users is
## 
##   @Article{,
##     title = {Graphical Independence Networks with the {gRain} Package for {R}},
##     author = {S{\o}ren H{\o}jsgaard},
##     journal = {Journal of Statistical Software},
##     year = {2012},
##     volume = {46},
##     number = {10},
##     pages = {1--26},
##     doi = {10.18637/jss.v046.i10},
##     url = {https://www.jstatsoft.org/v46/i10/},
##   }
\end{verbatim}
\end{kframe}
\end{knitrout}

Moreover, \cite{hoj:edw:lau:12} gives a broad treatment of graphical
models (including Bayesian networks) More information about the
package, other graphical modelling packages and development versions
is available from

\begin{quote}
\url{http://people.math.aau.dk/~sorenh/software/gR}
\end{quote}

%% \section{Two worked examples}
%% \label{sec:two-worked-examples}

%% \subsection{Wet grass}
%% \label{sec:wet-grass}

%% The `wet grass` example is motivated by the following narrative (taken from 
%% \url{https://en.wikipedia.org/wiki/Bayesian_network})
%% \begin{quote}
%%   Two events can cause grass to be wet: an active sprinkler or
%%   rain. Rain has a direct effect on the use of the sprinkler (namely
%%   that when it rains, the sprinkler usually is not active).
%% \end{quote}

%% <<echo=F, results='hide'>>=
%% p.R    <- cptable(~R, values=c(2, 8), levels=yn)
%% p.S_R  <- cptable(~S:R, values=c(1, 99, 4, 6), levels=yn)
%% p.G_SR <- cptable(~G:S:R, values=c(99, 1, 8, 2, 9, 1, 0, 1), levels=yn)
%% grass_bn <- compileCPT(p.R, p.S_R, p.G_SR)  %>% grain
%% @ 

%% <<chest-grass, fig.height=2, echo=F, fig.cap="Wet graph example; taken from Wikipedia.">>=
%% plot(grass_bn)
%% @ %def


\section{Example: Chest clinic}
\label{sec:chest-clinic}
\label{sec:chest}

% <<echo=F, results='hide'>>=
% yn <- c("yes","no")
% a    <- cptable(~asia, values=c(1,99),levels=yn)
% t.a  <- cptable(~tub|asia, values=c(5,95,1,99),levels=yn)
% s    <- cptable(~smoke, values=c(5,5), levels=yn)
% l.s  <- cptable(~lung|smoke, values=c(1,9,1,99), levels=yn)
% b.s  <- cptable(~bronc|smoke, values=c(6,4,3,7), levels=yn)
% e.lt <- cptable(~either|lung:tub,values=c(1,0,1,0,1,0,0,1),levels=yn)
% x.e  <- cptable(~xray|either, values=c(98,2,5,95), levels=yn)
% d.be <- cptable(~dysp|bronc:either, values=c(9,1,7,3,8,2,1,9), levels=yn)
% plist <- compileCPT(list(a, t.a, s, l.s, b.s, e.lt, x.e, d.be))
% plist
% chest_bn <- grain(plist)
% chest_bn
% @ %def












This section reviews the chest clinic example of \cite{lau/spieg:88}
(illustrated in Figure~\ref{fig:chest-LS}) and shows one way of
specifying the model in \grbn{}.  \cite{lau/spieg:88} motivate the
chest clinic example with the following narrative:

\begin{quote}
  ``Shortness--of--breath (dyspnoea) may be due to tuberculosis, lung
  cancer or bronchitis, or none of them, or more than one of them. A
  recent visit to Asia increases the chances of tuberculosis, while
  smoking is known to be a risk factor for both lung cancer and
  bronchitis. The results of a single chest X--ray do not discriminate
  between lung cancer and tuberculosis, as neither does the presence or
  absence of dyspnoea.''
\end{quote}


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{figure}
\includegraphics[width=\maxwidth]{figures/grain-chest-LS-1} \caption[Chest clinic example from Lauritzen and Spiegelhalter (1988)]{Chest clinic example from Lauritzen and Spiegelhalter (1988).}\label{fig:chest-LS}
\end{figure}

\end{knitrout}

\subsection{Building a network}

The description above involves the following binary variables:
$\alpha=\mbox{asia}$,
$\sigma=\mbox{smoker}$,
$\tau=\mbox{tuberculosis}$,
$\lambda=\mbox{lung cancer}$,
$\beta=\mbox{bronchitis}$,
$\epsilon=\mbox{either tuberculosis or lung cancer}$,
$\delta=\mbox{dyspnoea}$ and
$\xi=\mbox{xray}$. 
Each variable is binary and can take the values ``yes'' and ``no'':
Note that $\epsilon$ is a logical variable which is
true (yes) if either $\tau$ or $\lambda$ are true (yes) and false (no) otherwise.
The connection between the variables is displayed by the DAG (directed acyclic graph) in
Figure~\ref{fig:chest-LS}.

A joint probability density factorising accoring to a DAG with nodes
$V$ can be constructed as follows: Each node $v\in V$ has a set $pa(v)$ of parents and each node
$v\in V$ has a finite set of states. A joint distribution
over the variables $V$ can be given as
\begin{equation}
  \label{eq:dagfact1}
  p(V) = \prod_{v\in V} p(v|pa(v))
\end{equation}
where $p(v|pa(v))$ is a function defined on $(v,pa(v))$. This function
satisfies that $\sum_{v^*} p(v=v^*|pa(v))=1$, i.e.\ that
for each configuration of the parents $pa(v)$, the sum
over the levels of $v$ equals one. Hence $p(v|pa(v))$ becomes the
conditional distribution of $v$ given $pa(v)$.
In practice $p(v|pa(v))$ is specified as a table called a conditional
probability table or a CPT for short.
Thus, a Bayesian network can be regarded as a complex stochastic model built up by
putting together simple components (conditional probability
distributions).
A joint probability density for all eight variables in
Figure~\ref{fig:chest-LS}
can be constructed as 
\begin{equation}
  \label{eq:chestfact1}
  p(V) =
  p(\alpha)p(\sigma)p(\tau|\alpha)p(\lambda|\sigma)p(\beta|\sigma)p(\epsilon|\tau,\lambda)
  p(\delta|\epsilon, \beta)p(\xi|\epsilon).
\end{equation}



\subsection{Queries to networks}
\label{sec:xxx}

Suppose we are given the evidence (sometimes also called ``finding'')
that a set of variables $E\subset V$
have a specific value $e^*$.
With this evidence, we are often interested in the conditional
distribution $p(v|E=e^*)$
for some of the variables $v \in V \setminus E$
or in $p(U|E=e^*)$
for a set $U\subset V \setminus E$. Interest might also be in
calculating the probability of a specific event, e.g.\ the probability
of seeing a specific evidence, i.e.\ $p(E=e^*)$.
Other types of evidence (called soft evidence, virtual evidence or likelihood evidence) are discussed in
Section~\ref{sec:hard-virt-likel}.

For
example that a person has recently visited Asia and suffers from
dyspnoea, i.e.\ $\alpha=\mbox{yes}$ and $\delta=\mbox{yes}$.
In the chest clinic example, interest might be in $p(\lambda|e^*)$, $p(\tau|e^*)$
and  $p(\beta|e^*)$, or possibly in the joint (conditional) distribution
$p(\lambda,\tau,\beta|e^*)$.


\section{A one--minute version of  \grbn{}}
\label{sec:oneminute}

\subsection{Specifying a network}
\label{sec:specifying-network}

A simple way of  specifying the model for the chest clinic
example is as follows.

\begin{enumerate}
\item Specify conditional probability tables (with values as given in
  \cite{lau/spieg:88}) (there are other ways of specifying conditional
  probability tables, see the package documentation):

% <<echo=FALSE, results='hide'>>=
% yn <- c("yes", "no")
% a    <- cptable(~asia, values=c(1, 99), levels=yn)
% t.a  <- cptable(~tub|asia, values=c(5, 95, 1, 99), levels=yn)
% s    <- cptable(~smoke, values=c(5, 5), levels=yn)
% l.s  <- cptable(~lung|smoke, values=c(1, 9, 1, 99), levels=yn)
% b.s  <- cptable(~bronc|smoke, values=c(6, 4, 3, 7), levels=yn)
% e.lt <- cptable(~either|lung:tub, values=c(1, 0, 1, 0, 1, 0, 0, 1), levels=yn)
% x.e  <- cptable(~xray|either, values=c(98, 2, 5, 95), levels=yn)
% d.be <- cptable(~dysp|bronc:either, values=c(9, 1, 7, 3, 8, 2, 1, 9), levels=yn)
% @ %def




\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{yn} \hlkwb{<-} \hlkwd{c}\hlstd{(}\hlstr{"yes"}\hlstd{,}\hlstr{"no"}\hlstd{)}
\hlstd{a}    \hlkwb{<-} \hlkwd{cpt}\hlstd{(}\hlopt{~}\hlstd{asia,} \hlkwc{values}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,} \hlnum{99}\hlstd{),}\hlkwc{levels}\hlstd{=yn)}
\hlstd{t.a}  \hlkwb{<-} \hlkwd{cpt}\hlstd{(}\hlopt{~}\hlstd{tub}\hlopt{|}\hlstd{asia,} \hlkwc{values}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{5}\hlstd{,} \hlnum{95}\hlstd{,} \hlnum{1}\hlstd{,} \hlnum{99}\hlstd{),}\hlkwc{levels}\hlstd{=yn)}
\hlstd{s}    \hlkwb{<-} \hlkwd{cpt}\hlstd{(}\hlopt{~}\hlstd{smoke,} \hlkwc{values}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{5}\hlstd{,} \hlnum{5}\hlstd{),} \hlkwc{levels}\hlstd{=yn)}
\hlstd{l.s}  \hlkwb{<-} \hlkwd{cpt}\hlstd{(}\hlopt{~}\hlstd{lung}\hlopt{|}\hlstd{smoke,} \hlkwc{values}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,} \hlnum{9}\hlstd{,} \hlnum{1}\hlstd{,} \hlnum{99}\hlstd{),} \hlkwc{levels}\hlstd{=yn)}
\hlstd{b.s}  \hlkwb{<-} \hlkwd{cpt}\hlstd{(}\hlopt{~}\hlstd{bronc}\hlopt{|}\hlstd{smoke,} \hlkwc{values}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{6}\hlstd{,} \hlnum{4}\hlstd{,} \hlnum{3}\hlstd{,} \hlnum{7}\hlstd{),} \hlkwc{levels}\hlstd{=yn)}
\hlstd{e.lt} \hlkwb{<-} \hlkwd{cpt}\hlstd{(}\hlopt{~}\hlstd{either}\hlopt{|}\hlstd{lung}\hlopt{:}\hlstd{tub,}\hlkwc{values}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,} \hlnum{0}\hlstd{,} \hlnum{1}\hlstd{,} \hlnum{0}\hlstd{,} \hlnum{1}\hlstd{,} \hlnum{0}\hlstd{,} \hlnum{0}\hlstd{,} \hlnum{1}\hlstd{),}\hlkwc{levels}\hlstd{=yn)}
\hlstd{x.e}  \hlkwb{<-} \hlkwd{cpt}\hlstd{(}\hlopt{~}\hlstd{xray}\hlopt{|}\hlstd{either,} \hlkwc{values}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{98}\hlstd{,} \hlnum{2}\hlstd{,} \hlnum{5}\hlstd{,} \hlnum{95}\hlstd{),} \hlkwc{levels}\hlstd{=yn)}
\hlstd{d.be} \hlkwb{<-} \hlkwd{cpt}\hlstd{(}\hlopt{~}\hlstd{dysp}\hlopt{|}\hlstd{bronc}\hlopt{:}\hlstd{either,} \hlkwc{values}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{9}\hlstd{,} \hlnum{1}\hlstd{,} \hlnum{7}\hlstd{,} \hlnum{3}\hlstd{,} \hlnum{8}\hlstd{,} \hlnum{2}\hlstd{,} \hlnum{1}\hlstd{,} \hlnum{9}\hlstd{),} \hlkwc{levels}\hlstd{=yn)}
\end{alltt}
\end{kframe}
\end{knitrout}

\item Compile list of conditional probability tables.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{chest_cpt} \hlkwb{<-} \hlkwd{compileCPT}\hlstd{(a, t.a, s, l.s, b.s, e.lt, x.e, d.be)}
\hlstd{chest_cpt}
\end{alltt}
\begin{verbatim}
##  P( asia )
##  P( tub | asia )
##  P( smoke )
##  P( lung | smoke )
##  P( bronc | smoke )
##  P( either | lung tub )
##  P( xray | either )
##  P( dysp | bronc either )
\end{verbatim}
\end{kframe}
\end{knitrout}

The components are arrays, but coercion into dataframes sometimes makes it easier to digest the components.
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{chest_cpt}\hlopt{$}\hlstd{tub}
\end{alltt}
\begin{verbatim}
##      asia
## tub    yes   no
##   yes 0.05 0.01
##   no  0.95 0.99
\end{verbatim}
\begin{alltt}
\hlstd{chest_cpt}\hlopt{$}\hlstd{tub  |>} \hlkwd{as.data.frame.table}\hlstd{()}
\end{alltt}
\begin{verbatim}
##   tub asia Freq
## 1 yes  yes 0.05
## 2  no  yes 0.95
## 3 yes   no 0.01
## 4  no   no 0.99
\end{verbatim}
\end{kframe}
\end{knitrout}

Notice: \code{either} is a logical node:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{chest_cpt}\hlopt{$}\hlstd{either  |>} \hlkwd{as.data.frame.table}\hlstd{()}
\end{alltt}
\begin{verbatim}
##   either lung tub Freq
## 1    yes  yes yes    1
## 2     no  yes yes    0
## 3    yes   no yes    1
## 4     no   no yes    0
## 5    yes  yes  no    1
## 6     no  yes  no    0
## 7    yes   no  no    0
## 8     no   no  no    1
\end{verbatim}
\end{kframe}
\end{knitrout}


\item Create the network:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{chest_bn} \hlkwb{<-} \hlkwd{grain}\hlstd{(chest_cpt)}
\hlstd{chest_bn}
\end{alltt}
\begin{verbatim}
## Independence network: Compiled: TRUE Propagated: FALSE Evidence: FALSE
\end{verbatim}
\end{kframe}
\end{knitrout}

Default is that the network is compiled at creation time, but if one
chooses not to do so, compilation can be done with:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{chest_bn} \hlkwb{<-} \hlkwd{compile}\hlstd{(chest_bn)}
\end{alltt}
\end{kframe}
\end{knitrout}

\end{enumerate}

\subsection{Setting evidence and querying a network}
\label{sec:querying-network}

\begin{enumerate}
\item A network can be queried to give marginal probabilities for
  each of a set of nodes (the default) or the joint probability for a
  set of nodes.\footnote{A third type of output exists, see package
    documentation for details.}  Notice that \code{querygrain()} can
  be abbreviated \code{qgrain()}.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{querygrain}\hlstd{(chest_bn,} \hlkwc{nodes}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"lung"}\hlstd{,} \hlstr{"bronc"}\hlstd{),} \hlkwc{type}\hlstd{=}\hlstr{"marginal"}\hlstd{)}
\end{alltt}
\begin{verbatim}
## $lung
## lung
##   yes    no 
## 0.055 0.945 
## 
## $bronc
## bronc
##  yes   no 
## 0.45 0.55
\end{verbatim}
\end{kframe}
\end{knitrout}


\item Likewise, a joint distribution can be obtained (represented as a
  multi dimensional array):

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{querygrain}\hlstd{(chest_bn,} \hlkwc{nodes}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"lung"}\hlstd{,} \hlstr{"bronc"}\hlstd{),} \hlkwc{type}\hlstd{=}\hlstr{"joint"}\hlstd{)}
\end{alltt}
\begin{verbatim}
##      bronc
## lung     yes     no
##   yes 0.0315 0.0235
##   no  0.4185 0.5265
\end{verbatim}
\end{kframe}
\end{knitrout}

\item Evidence can be entered in two different ways:\footnote{Alternative forms
    exist; see package documentation for details.}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{chest_ev}  \hlkwb{<-} \hlkwd{setEvidence}\hlstd{(chest_bn,}
                          \hlkwc{evidence}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{asia}\hlstd{=}\hlstr{"yes"}\hlstd{,} \hlkwc{dysp}\hlstd{=}\hlstr{"yes"}\hlstd{))}
\hlstd{chest_ev}  \hlkwb{<-} \hlkwd{setEvidence}\hlstd{(chest_bn,}
                          \hlkwc{nodes}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"asia"}\hlstd{,} \hlstr{"dysp"}\hlstd{),} \hlkwc{states}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"yes"}\hlstd{,} \hlstr{"yes"}\hlstd{))}

\hlcom{## Also: modify object with}
\hlcom{## evidence(chest_bn) <- list(asia="yes", dysp="yes")}
\end{alltt}
\end{kframe}
\end{knitrout}

\item The evidence is a list and can conveniently be displayed as a dataframe:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{getEvidence}\hlstd{(chest_ev) |>} \hlkwd{as.data.frame}\hlstd{()}
\end{alltt}
\begin{verbatim}
##   nodes is_hard hard_state evi_weight
## 1  asia    TRUE        yes       1, 0
## 2  dysp    TRUE        yes       1, 0
\end{verbatim}
\end{kframe}
\end{knitrout}

\item The network can be queried again:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{querygrain}\hlstd{(chest_ev,} \hlkwc{nodes}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"lung"}\hlstd{,} \hlstr{"bronc"}\hlstd{))}
\end{alltt}
\begin{verbatim}
## $lung
## lung
##        yes         no 
## 0.09952515 0.90047485 
## 
## $bronc
## bronc
##       yes        no 
## 0.8114021 0.1885979
\end{verbatim}
\end{kframe}
\end{knitrout}


\item The probability of observing this evidence under the model is
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{pEvidence}\hlstd{(chest_ev)}
\end{alltt}
\begin{verbatim}
## [1] 0.004501375
\end{verbatim}
\end{kframe}
\end{knitrout}

\item The probability of an evidence can be found with only
  propagation towards the root of a junction tree. This saves about
  half the computational effort of propagation:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{pEvidence}\hlstd{(chest_bn,} \hlkwc{evidence}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{asia}\hlstd{=}\hlstr{"yes"}\hlstd{,} \hlkwc{dysp}\hlstd{=}\hlstr{"yes"}\hlstd{))}
\end{alltt}
\begin{verbatim}
## [1] 0.004501375
\end{verbatim}
\end{kframe}
\end{knitrout}


\end{enumerate}


\section{Hints and shortcuts}
\label{sec:small-shortcuts}

\begin{enumerate}
\item An alternative way of specifying a network is by first defining CPTs and then entering values afterwards. Programmatically, this can be done as:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{yn} \hlkwb{<-} \hlkwd{c}\hlstd{(}\hlstr{"yes"}\hlstd{,}\hlstr{"no"}\hlstd{)}
\hlstd{flist} \hlkwb{<-} \hlkwd{c}\hlstd{(}
    \hlopt{~}\hlstd{asia,} \hlopt{~}\hlstd{tub}\hlopt{|}\hlstd{asia,} \hlopt{~}\hlstd{smoke,} \hlopt{~}\hlstd{lung}\hlopt{|}\hlstd{smoke,} \hlopt{~}\hlstd{bronc}\hlopt{|}\hlstd{smoke,} \hlopt{~}\hlstd{either}\hlopt{|}\hlstd{lung}\hlopt{:}\hlstd{tub,}
    \hlopt{~}\hlstd{xray}\hlopt{|}\hlstd{either,} \hlopt{~}\hlstd{dysp}\hlopt{|}\hlstd{bronc}\hlopt{:}\hlstd{either}
\hlstd{)}
\hlcom{## or}
\hlstd{flist} \hlkwb{<-} \hlkwd{list}\hlstd{(}\hlstr{"asia"}\hlstd{,} \hlkwd{c}\hlstd{(}\hlstr{"tub"}\hlstd{,} \hlstr{"asia"}\hlstd{),} \hlstr{"smoke"}\hlstd{,} \hlkwd{c}\hlstd{(}\hlstr{"lung"}\hlstd{,} \hlstr{"smoke"}\hlstd{),}
              \hlkwd{c}\hlstd{(}\hlstr{"bronc"}\hlstd{,} \hlstr{"smoke"}\hlstd{),} \hlkwd{c}\hlstd{(}\hlstr{"either"}\hlstd{,} \hlstr{"tub"}\hlstd{,} \hlstr{"lung"}\hlstd{),} \hlkwd{c}\hlstd{(}\hlstr{"xray"}\hlstd{,} \hlstr{"either"}\hlstd{),}
              \hlkwd{c}\hlstd{(}\hlstr{"dysp"}\hlstd{,} \hlstr{"bronc"}\hlstd{,} \hlstr{"either"}\hlstd{))}

\hlstd{chest_cpt2} \hlkwb{<-} \hlkwd{lapply}\hlstd{(flist,} \hlkwa{function}\hlstd{(}\hlkwc{f}\hlstd{)\{}
    \hlkwd{cpt}\hlstd{(f,} \hlkwc{levels}\hlstd{=yn)}
\hlstd{\})}

\hlstd{bn2} \hlkwb{<-} \hlkwd{compileCPT}\hlstd{(chest_cpt2) |>} \hlkwd{grain}\hlstd{()}

\hlstd{lst2} \hlkwb{<-} \hlkwd{list}\hlstd{(}\hlkwc{asia}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,} \hlnum{99}\hlstd{),}
            \hlkwc{tub}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{5}\hlstd{,} \hlnum{95}\hlstd{,} \hlnum{1}\hlstd{,} \hlnum{99}\hlstd{),}
            \hlkwc{smoke}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{5}\hlstd{,} \hlnum{5}\hlstd{),}
            \hlkwc{lung}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,} \hlnum{9}\hlstd{,} \hlnum{1}\hlstd{,} \hlnum{99}\hlstd{),}
            \hlkwc{bronc}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{6}\hlstd{,} \hlnum{4}\hlstd{,} \hlnum{3}\hlstd{,} \hlnum{7}\hlstd{),}
            \hlkwc{either}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,} \hlnum{0}\hlstd{,} \hlnum{1}\hlstd{,} \hlnum{0}\hlstd{,} \hlnum{1}\hlstd{,} \hlnum{0}\hlstd{,} \hlnum{0}\hlstd{,} \hlnum{1}\hlstd{),}
            \hlkwc{xray}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{98}\hlstd{,} \hlnum{2}\hlstd{,} \hlnum{5}\hlstd{,} \hlnum{95}\hlstd{),}
            \hlkwc{dysp}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{9}\hlstd{,} \hlnum{1}\hlstd{,} \hlnum{7}\hlstd{,} \hlnum{3}\hlstd{,} \hlnum{8}\hlstd{,} \hlnum{2}\hlstd{,} \hlnum{1}\hlstd{,} \hlnum{9}\hlstd{))}

\hlstd{bn2} \hlkwb{<-} \hlkwd{replaceCPT}\hlstd{(bn2, lst2)}
\end{alltt}
\end{kframe}
\end{knitrout}

\item Consider querying a network where focus is on 
  marginal distributions (the default). If all variables have the same
  levels (as the case is here), the output can be coerced to a
  dataframe:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{querygrain}\hlstd{(chest_bn,} \hlkwc{nodes}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"lung"}\hlstd{,} \hlstr{"bronc"}\hlstd{),} \hlkwc{simplify} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\end{alltt}
\begin{verbatim}
##         yes    no
## lung  0.055 0.945
## bronc 0.450 0.550
\end{verbatim}
\end{kframe}
\end{knitrout}

In the more general case the output can be coerced to a list of dataframes
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{querygrain}\hlstd{(chest_bn,} \hlkwc{nodes}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"lung"}\hlstd{,} \hlstr{"bronc"}\hlstd{),} \hlkwc{result}\hlstd{=}\hlstr{"data.frame"}\hlstd{)}
\end{alltt}
\begin{verbatim}
## $lung
##   lung  Freq
## 1  yes 0.055
## 2   no 0.945
## 
## $bronc
##   bronc Freq
## 1   yes 0.45
## 2    no 0.55
\end{verbatim}
\end{kframe}
\end{knitrout}

\item A typical use of \bn\ involves setting evidence and then querying the network afterwards. This can all be done in one call of \code{querygrain}:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{querygrain}\hlstd{(chest_bn,}
           \hlkwc{evidence}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{asia}\hlstd{=}\hlstr{"yes"}\hlstd{,} \hlkwc{dysp}\hlstd{=}\hlstr{"yes"}\hlstd{),}
           \hlkwc{nodes}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"lung"}\hlstd{,} \hlstr{"bronc"}\hlstd{),} \hlkwc{simplify} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\end{alltt}
\begin{verbatim}
##              yes        no
## lung  0.09952515 0.9004749
## bronc 0.81140207 0.1885979
\end{verbatim}
\end{kframe}
\end{knitrout}

Evidence can be also be given as a vector of weights (cfr Section~\ref{sec:hard-soft})
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{querygrain}\hlstd{(chest_bn,}
           \hlkwc{evidence}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{asia}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,}\hlnum{0}\hlstd{),} \hlkwc{dysp}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,}\hlnum{0}\hlstd{)),}
           \hlkwc{nodes}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"lung"}\hlstd{,} \hlstr{"bronc"}\hlstd{),} \hlkwc{simplify} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\end{alltt}
\begin{verbatim}
##              yes        no
## lung  0.09952515 0.9004749
## bronc 0.81140207 0.1885979
\end{verbatim}
\end{kframe}
\end{knitrout}

Nodes on which evidence is given are are not reported unless \code{exclude=FALSE}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{querygrain}\hlstd{(chest_bn,}
           \hlkwc{evidence}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{asia}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,} \hlnum{0}\hlstd{),} \hlkwc{dysp}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,} \hlnum{0}\hlstd{)),}
           \hlkwc{nodes}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"lung"}\hlstd{,} \hlstr{"bronc"}\hlstd{,} \hlstr{"asia"}\hlstd{,} \hlstr{"dysp"}\hlstd{),}
           \hlkwc{exclude}\hlstd{=}\hlnum{FALSE}\hlstd{,} \hlkwc{simplify} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\end{alltt}
\begin{verbatim}
##              yes        no
## asia  1.00000000 0.0000000
## lung  0.09952515 0.9004749
## bronc 0.81140207 0.1885979
## dysp  1.00000000 0.0000000
\end{verbatim}
\end{kframe}
\end{knitrout}



If \code{nodes} are not specified, queries for all nodes without evidence are reported.
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{querygrain}\hlstd{(chest_bn,}
           \hlkwc{evidence}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{asia}\hlstd{=}\hlstr{"yes"}\hlstd{,} \hlkwc{dysp}\hlstd{=}\hlstr{"yes"}\hlstd{),}
           \hlkwc{simplify} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\end{alltt}
\begin{verbatim}
##               yes        no
## tub    0.08775096 0.9122490
## lung   0.09952515 0.9004749
## either 0.18229985 0.8177001
## bronc  0.81140207 0.1885979
## smoke  0.62591986 0.3740801
## xray   0.21953886 0.7804611
\end{verbatim}
\end{kframe}
\end{knitrout}

If \code{nodes} are not specified and \code{exclude=FALSE}, then queries for all nodes are reported.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{querygrain}\hlstd{(chest_bn,}
           \hlkwc{evidence}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{asia}\hlstd{=}\hlstr{"yes"}\hlstd{,} \hlkwc{dysp}\hlstd{=}\hlstr{"yes"}\hlstd{),}
           \hlkwc{exclude} \hlstd{=} \hlnum{FALSE}\hlstd{,} \hlkwc{simplify} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\end{alltt}
\begin{verbatim}
##               yes        no
## asia   1.00000000 0.0000000
## tub    0.08775096 0.9122490
## lung   0.09952515 0.9004749
## either 0.18229985 0.8177001
## bronc  0.81140207 0.1885979
## smoke  0.62591986 0.3740801
## dysp   1.00000000 0.0000000
## xray   0.21953886 0.7804611
\end{verbatim}
\end{kframe}
\end{knitrout}


\end{enumerate}



\section{Conditioning on evidence with zero probability}
\label{sec:zero-probabilities}

Consider setting the evidence
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{chest_bn3} \hlkwb{<-} \hlkwd{setEvidence}\hlstd{(chest_bn,} \hlkwc{evidence}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{either}\hlstd{=}\hlstr{"no"}\hlstd{,} \hlkwc{tub}\hlstd{=}\hlstr{"yes"}\hlstd{))}
\end{alltt}
\end{kframe}
\end{knitrout}

Under the model, this specific evidence has zero probability:
\verb|either| is true if \verb|tub| is true or \verb|lung| is true (or
both). Hence the specific evidence is impossible and therefore, all
conditional probabilities are (under the model) undefined:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{pEvidence}\hlstd{(chest_bn3)}
\end{alltt}
\begin{verbatim}
## [1] 0
\end{verbatim}
\begin{alltt}
\hlkwd{querygrain}\hlstd{(chest_bn3,} \hlkwc{nodes}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"lung"}\hlstd{,} \hlstr{"bronc"}\hlstd{),} \hlkwc{type}\hlstd{=}\hlstr{"joint"}\hlstd{)}
\end{alltt}
\begin{verbatim}
##      bronc
## lung  yes  no
##   yes NaN NaN
##   no  NaN NaN
\end{verbatim}
\end{kframe}
\end{knitrout}




\section{Hard  and virtual (likelihood) evidence}
\label{sec:hard-virt-likel}
\label{sec:hard-soft}

Below we describe  how to work with virtual evidence (also known
as soft evidence or likelihood evidence) in \grbn. This is done via the function
\code{setEvidence()}.

The clique potential representation in a Bayesian network gives
\begin{displaymath}
  p(x) \propto \psi(x) = \prod_{C} \psi_C(x_C).
\end{displaymath}

Here we recall that the whole idea in computations with Bayesian
networks is to avoid calculation the product on the right hand
side above. Instead computations are based on propagation (multiplying,
dividing and summing clique potentials $\psi_C$ in an appropriate
order, and such an appropriate order comes from a junction tree).
The normalizing constant, say $c=\sum_x \psi(x)$, comes out of
propagation as a ``by product''.

Suppose a set of nodes $E$ are known to have a specific value,
i.e. $x_E=x^*_E$. This is called hard evidence. The probability of
the event $x_E=x^*_E$ is
\begin{displaymath}
  p(x_E=x^*_E)=E_p\{I(x_E=x^*_E)\} = \sum_x I(x_E=x^*_E) p(x)
  = \frac{1}{c} \sum_x I(x_E=x^*_E) \psi(x)
\end{displaymath}

The computations are based on modifying the clique potentials $\psi_C$
by giving value zero to states in $\psi_C$ which are not consistent
with $x_E=x^*_E$. This can be achieved with an indicator function, say
$L_C(x_C)$ such that we obtain a set of new potentials $\tilde \psi_C(x)
= L_C(x_C) \psi_C(x_C)$. Propagation with these new potentials gives,
as a by product, $\tilde c=\sum \tilde \psi(x)$ where
$\tilde\psi(x)= \prod_C \tilde\psi_C(x_C)$. Consequently, we have
$p(x_E=x^*_E)=\tilde c / c$.

In a more general setting we may have non--negative weights $L(x)$ for
each value of $x$. We may calculate
\begin{displaymath}
  E_p\{L(X)\} = \sum_x L(x)p(x)
\end{displaymath}
If $L(X)$ factorizes as $L(X)= \prod_C L_C(X_C)$ then the computations are
carried out as outlined above, i.e.\ by the message passing scheme.


\subsection{An excerpt of the chest clinic network}
\label{sec:an-excerpt-chest}


Consider the following excerpt of the chest clinic network.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{yn} \hlkwb{<-} \hlkwd{c}\hlstd{(}\hlstr{"yes"}\hlstd{,} \hlstr{"no"}\hlstd{)}
\hlstd{a}    \hlkwb{<-} \hlkwd{cpt}\hlstd{(}\hlopt{~}\hlstd{asia,} \hlkwc{values}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,} \hlnum{99}\hlstd{),} \hlkwc{levels}\hlstd{=yn)}
\hlstd{t.a}  \hlkwb{<-} \hlkwd{cpt}\hlstd{(}\hlopt{~}\hlstd{tub}\hlopt{|}\hlstd{asia,} \hlkwc{values}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{5}\hlstd{,} \hlnum{95}\hlstd{,} \hlnum{1}\hlstd{,} \hlnum{99}\hlstd{),} \hlkwc{levels}\hlstd{=yn)}

\hlstd{plist1} \hlkwb{<-} \hlkwd{compileCPT}\hlstd{(}\hlkwd{list}\hlstd{(a, t.a))}
\hlstd{chest1} \hlkwb{<-} \hlkwd{grain}\hlstd{(plist1)}
\hlkwd{querygrain}\hlstd{(chest1,} \hlkwc{simplify} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\end{alltt}
\begin{verbatim}
##         yes     no
## asia 0.0100 0.9900
## tub  0.0104 0.9896
\end{verbatim}
\end{kframe}
\end{knitrout}

\subsection{Specifying hard evidence} 
\label{sec:hard-evidence}

Suppose we want to make a diagnosis about tuberculosis given the evidence that a person has recently been to Asia.
The function \code{setEvidence()} can  be used for this purpose. The following forms are equivalent

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{setEvidence}\hlstd{(chest1,} \hlkwc{evidence}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{asia}\hlstd{=}\hlstr{"yes"}\hlstd{))}
\end{alltt}
\begin{verbatim}
## Independence network: Compiled: TRUE Propagated: TRUE Evidence: TRUE
\end{verbatim}
\end{kframe}
\end{knitrout}

We call such evidence hard evidence because the state of the variables are known with certainty.


% <<>>=
% querygrain(chest1, nodes="tub", simplify = TRUE)
% querygrain(chest1, evidence=list(asia="yes"), simplify = TRUE)
% @ %def

\subsection{Virtual evidence (also called soft or likelihood evidence)}
\label{sec:virt-evid-likel}

Suppose we do not know with certainty whether a patient has
recently been to Asia (perhaps the patient is too ill to
tell). However the patient (if he/she is Caucasian) may be unusually
tanned and this lends support to the hypothesis of a recent visit to
Asia.

To accommodate this setting we create an extended network with an extra
node for which we enter evidence.


However, it is NOT necessary to do
so in practice, because we may equivalently enter the virtual evidence
in the original network.

We can then introduce a new variable
\code{guess\_asia} with \code{asia} as its only parent.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{g.a} \hlkwb{<-} \hlkwd{cpt}\hlstd{(}\hlopt{~}\hlstd{guess_asia}\hlopt{+}\hlstd{asia,} \hlkwc{levels}\hlstd{=yn,}
              \hlkwc{values}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{.8}\hlstd{,} \hlnum{.2}\hlstd{,} \hlnum{.1}\hlstd{,} \hlnum{.9}\hlstd{))}
\end{alltt}
\end{kframe}
\end{knitrout}

This reflects the assumption that for patients who have recently been
to Asia we would (correctly) guess so in 80\% of the cases, whereas for patients who have
not recently been to A we would (erroneously) guess that they have
recently been to Asia in 10\% of the cases.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{plist2} \hlkwb{<-} \hlkwd{compileCPT}\hlstd{(}\hlkwd{list}\hlstd{(a, t.a, g.a ))}
\hlstd{chest2} \hlkwb{<-} \hlkwd{grain}\hlstd{(plist2)}
\hlkwd{querygrain}\hlstd{(chest2,} \hlkwc{simplify} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\end{alltt}
\begin{verbatim}
##               yes     no
## asia       0.0100 0.9900
## tub        0.0104 0.9896
## guess_asia 0.1070 0.8930
\end{verbatim}
\end{kframe}
\end{knitrout}


Now specify the guess or judgment, that the person has recently been
to Asia:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{querygrain}\hlstd{(chest2,} \hlkwc{evidence}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{guess_asia}\hlstd{=}\hlstr{"yes"}\hlstd{),}
           \hlkwc{simplify}\hlstd{=}\hlnum{TRUE}\hlstd{,} \hlkwc{exclude} \hlstd{=} \hlnum{FALSE}\hlstd{)}
\end{alltt}
\begin{verbatim}
##                   yes        no
## asia       0.07476636 0.9252336
## tub        0.01299065 0.9870093
## guess_asia 1.00000000 0.0000000
\end{verbatim}
\end{kframe}
\end{knitrout}

\subsection{Specifying virtual evidence}
\label{sec:spec-virt-evid}

The same guess or judgment can be specified as virtual evidence
(also called likelihood evidence) for the original network:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{chest1_ve} \hlkwb{<-} \hlstd{chest1 |>} \hlkwd{setEvidence}\hlstd{(}\hlkwc{evidence}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{asia}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{.8}\hlstd{,} \hlnum{.1}\hlstd{)))}
\hlstd{chest1_ve |>} \hlkwd{querygrain}\hlstd{(}\hlkwc{simplify} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\end{alltt}
\begin{verbatim}
##            yes        no
## tub 0.01299065 0.9870093
\end{verbatim}
\begin{alltt}
\hlkwd{getEvidence}\hlstd{(chest1_ve,} \hlkwc{short}\hlstd{=}\hlnum{FALSE}\hlstd{)}
\end{alltt}
\begin{verbatim}
## $nodes
## [1] "asia"
## 
## $is_hard
## [1] FALSE
## 
## $hard_state
## [1] NA
## 
## $evi_weight
## $evi_weight[[1]]
## asia
## yes  no 
## 0.8 0.1 
## 
## 
## attr(,"class")
## [1] "grain_evidence" "list"
\end{verbatim}
\end{kframe}
\end{knitrout}

This also means that specifying that specifying \code{asia='yes'} can
be done as
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{querygrain}\hlstd{(chest1,} \hlkwc{evidence}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{asia}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,} \hlnum{0}\hlstd{)),} \hlkwc{simplify}\hlstd{=T)}
\end{alltt}
\begin{verbatim}
##      yes   no
## tub 0.05 0.95
\end{verbatim}
\end{kframe}
\end{knitrout}

\subsection{Extending networks to include other types of variables}
\label{sec:ixture}

\grbn\ only handles discrete variables with a finite state space, but
using likelihood evidence it is possible to work with networks with
both discrete and continuous variables (or other types of variables).
This is possible only when he networks have a specific structure. This
is possible when no discrete variable has non--discrete parents.

Take a simple example: Form a \bn\ for variables $x=(x_1, x_2)$. 
Conceptually augment this network with additional variables $y=(y_1, y_2)$ where
$y_1|x_1=k \sim N(\mu_k, v)$ and
$y_2|x_2=k \sim Poi(\lambda_k)$ for $k=1,2$. Also we make the assumption
that $y_1$ and $y_2$ are independent given $x=(x_1, x_2)$. This gives the DAG
below:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{plot}\hlstd{(}\hlkwd{dag}\hlstd{(}\hlopt{~}\hlstd{y1}\hlopt{:}\hlstd{x1} \hlopt{+} \hlstd{x2}\hlopt{:}\hlstd{x1} \hlopt{+} \hlstd{y2}\hlopt{:}\hlstd{x2))}
\end{alltt}
\end{kframe}
\includegraphics[width=\maxwidth]{figures/grain-unnamed-chunk-35-1} 
\end{knitrout}


A \bn\ for $x$ can be constructed as:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{u} \hlkwb{<-} \hlkwd{list}\hlstd{(}\hlkwc{x1}\hlstd{=yn,} \hlkwc{x2}\hlstd{=yn)}
\hlstd{x1} \hlkwb{<-} \hlkwd{cpt}\hlstd{(}\hlopt{~}\hlstd{x1,} \hlkwc{values}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,} \hlnum{3}\hlstd{),} \hlkwc{levels}\hlstd{=yn)}
\hlstd{x2} \hlkwb{<-} \hlkwd{cpt}\hlstd{(}\hlopt{~}\hlstd{x2}\hlopt{|}\hlstd{x1,} \hlkwc{values}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,} \hlnum{3}\hlstd{,} \hlnum{3}\hlstd{,} \hlnum{1}\hlstd{),} \hlkwc{levels}\hlstd{=yn)}
\hlstd{bn} \hlkwb{<-} \hlkwd{grain}\hlstd{(}\hlkwd{compileCPT}\hlstd{(x1, x2))}
\hlkwd{querygrain}\hlstd{(bn,} \hlkwc{simplify}\hlstd{=}\hlnum{TRUE}\hlstd{)}
\end{alltt}
\begin{verbatim}
##      yes    no
## x1 0.250 0.750
## x2 0.625 0.375
\end{verbatim}
\end{kframe}
\end{knitrout}

The augmentation of $y|x$ can go along these lines: The parameters describing $y|x$ are set to be:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{v} \hlkwb{<-} \hlnum{2}
\hlstd{mu} \hlkwb{<-} \hlkwd{c}\hlstd{(}\hlkwc{mu1}\hlstd{=}\hlnum{2}\hlstd{,} \hlkwc{mu2}\hlstd{=}\hlnum{5}\hlstd{)}
\hlstd{lambda} \hlkwb{<-} \hlkwd{c}\hlstd{(}\hlkwc{lambda1}\hlstd{=}\hlnum{0}\hlstd{,} \hlkwc{lambda2}\hlstd{=}\hlnum{7}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

Suppose we observe $y_1 = y_1^*$. Then
\begin{displaymath}
  p(x|y_1= y_1^*)\propto p(x_1)p(x_2|x_1) p(y_1=y_1^*|x_1) =  p(x_1)p(x_2|x_1) L_1(x_1)
\end{displaymath}
where $L_1(x_1)$ denotes the likelihood. In a \bn\ setting this
corresponds to changing $p(x_1)$ as
\begin{displaymath}
  p(x_1) \leftarrow p(x_1)L_1(x_1)
\end{displaymath}
and then carry on with propagation. This can be achieved in different ways. One is by setting the likelihood as evidence:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{y1} \hlkwb{<-} \hlnum{1} \hlcom{# Observed value for y1}
\hlstd{lik1} \hlkwb{<-} \hlkwd{dnorm}\hlstd{(y1,} \hlkwc{mean}\hlstd{=mu,} \hlkwc{sd}\hlstd{=}\hlkwd{sqrt}\hlstd{(v))}
\hlkwd{querygrain}\hlstd{(bn,} \hlkwc{exclude} \hlstd{=} \hlnum{FALSE}\hlstd{,}
           \hlkwc{evidence}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{x1}\hlstd{=lik1),} \hlkwc{simplify} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\end{alltt}
\begin{verbatim}
##          yes         no
## x1 0.9340965 0.06590353
## x2 0.2829518 0.71704823
\end{verbatim}
\end{kframe}
\end{knitrout}

An alternative is to explicitly modify the CPT which specifies $p(x_1)$:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{x1_upd} \hlkwb{<-} \hlkwd{getgrain}\hlstd{(bn,} \hlstr{"cptlist"}\hlstd{)}\hlopt{$}\hlstd{x1} \hlopt{*} \hlstd{lik1}
\hlstd{bn2} \hlkwb{<-} \hlkwd{replaceCPT}\hlstd{(bn,} \hlkwd{list}\hlstd{(}\hlkwc{x1}\hlstd{=x1_upd))}
\hlkwd{querygrain}\hlstd{(bn2)}
\end{alltt}
\begin{verbatim}
## $x1
## x1
##        yes         no 
## 0.93409647 0.06590353 
## 
## $x2
## x2
##       yes        no 
## 0.2829518 0.7170482
\end{verbatim}
\end{kframe}
\end{knitrout}

A final remark: The conditional distribtion of
$y_1$ is normal, but the unconditional distribtion is a mixture of
normals. Likewise, the conditional distribution of
$y_2$ is poisson, but the unconditional distribtion is a mixture of
poissons. Evidence on, say $y_1$ changes the belief in $x_1$ and
$x_2$ and this in turn changes the distribution of
$y_2$ (evidence changes the mixture weights.)  


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{set.seed}\hlstd{(}\hlnum{2022}\hlstd{)}
\hlstd{nsim} \hlkwb{<-} \hlnum{1000}
\hlstd{xsim1} \hlkwb{<-} \hlkwd{simulate}\hlstd{(bn, nsim)}
\hlkwd{head}\hlstd{(xsim1)}
\end{alltt}
\begin{verbatim}
##   x1  x2
## 1 no yes
## 2 no yes
## 3 no yes
## 4 no yes
## 5 no yes
## 6 no yes
\end{verbatim}
\begin{alltt}
\hlstd{xsim2} \hlkwb{<-} \hlkwd{simulate}\hlstd{(bn2, nsim)}
\hlkwd{head}\hlstd{(xsim2)}
\end{alltt}
\begin{verbatim}
##    x1  x2
## 1 yes  no
## 2  no yes
## 3 yes  no
## 4 yes  no
## 5  no yes
## 6 yes  no
\end{verbatim}
\begin{alltt}
\hlkwd{par}\hlstd{(}\hlkwc{mfrow}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,}\hlnum{2}\hlstd{))}
\hlstd{y2sim} \hlkwb{<-} \hlkwd{rpois}\hlstd{(}\hlkwc{n}\hlstd{=nsim,} \hlkwc{lambda}\hlstd{=lambda[xsim1}\hlopt{$}\hlstd{x2])}
\hlstd{y22sim} \hlkwb{<-} \hlkwd{rpois}\hlstd{(}\hlkwc{n}\hlstd{=nsim,} \hlkwc{lambda}\hlstd{=lambda[xsim2}\hlopt{$}\hlstd{x2])}
\hlstd{y2sim |>} \hlkwd{hist}\hlstd{(}\hlkwc{prob}\hlstd{=T,} \hlkwc{ylim}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,} \hlnum{.4}\hlstd{),} \hlkwc{breaks}\hlstd{=}\hlnum{10}\hlstd{)}
\hlstd{y22sim |>} \hlkwd{hist}\hlstd{(}\hlkwc{prob}\hlstd{=T,} \hlkwc{ylim}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,} \hlnum{.4}\hlstd{),} \hlkwc{breaks}\hlstd{=}\hlnum{10}\hlstd{)}
\end{alltt}
\end{kframe}
\includegraphics[width=\maxwidth]{figures/grain-unnamed-chunk-40-1} 
\end{knitrout}








The joint distribution is
\begin{displaymath}
  p(x,y_1, y_2) = p(x)p(y_1|x)p(y_2|x)
\end{displaymath}

Suppose the interest is in the distribution of $x$ given
$y_1=y_1^*$ and $y_2=y_2^*$. We then have
\begin{displaymath}
  p(x|y_1^*, y_2^*) \propto p(x) p(y_1^*|x)p(y_2^*|x) =
  p(x) L_1(x) L_2(x)
\end{displaymath}





\section{Building networks from data}
\label{sec:using-textttsm-argum}

The following two graphs specify the same model:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{dG}  \hlkwb{<-} \hlkwd{dag}\hlstd{(}\hlopt{~}\hlstd{A}\hlopt{:}\hlstd{B} \hlopt{+} \hlstd{B}\hlopt{:}\hlstd{C)}
\hlstd{uG}  \hlkwb{<-} \hlkwd{ug}\hlstd{(}\hlopt{~}\hlstd{A}\hlopt{:}\hlstd{B} \hlopt{+} \hlstd{B}\hlopt{:}\hlstd{C)}
\hlkwd{par}\hlstd{(}\hlkwc{mfrow}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,}\hlnum{2}\hlstd{));} \hlkwd{plot}\hlstd{( dG );} \hlkwd{plot}\hlstd{( uG )}
\end{alltt}
\end{kframe}
\includegraphics[width=\maxwidth]{figures/grain-unnamed-chunk-41-1} 
\end{knitrout}

Suppose data is
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{dat} \hlkwb{<-} \hlkwd{tabNew}\hlstd{(}\hlkwd{c}\hlstd{(}\hlstr{"A"}\hlstd{,} \hlstr{"B"}\hlstd{,} \hlstr{"C"}\hlstd{),} \hlkwc{levels}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{"lev1"}\hlstd{,} \hlstr{"lev2"}\hlstd{),} \hlcom{#levels=c(2,2,2),}
              \hlkwc{values}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,} \hlnum{0}\hlstd{,} \hlnum{2}\hlstd{,} \hlnum{3}\hlstd{,} \hlnum{1}\hlstd{,} \hlnum{2}\hlstd{,} \hlnum{1}\hlstd{,} \hlnum{4}\hlstd{))}
\hlkwd{class}\hlstd{(dat)}
\end{alltt}
\begin{verbatim}
## [1] "array"
\end{verbatim}
\end{kframe}
\end{knitrout}

A network can be built from data using:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{gr.dG} \hlkwb{<-} \hlkwd{compile}\hlstd{(}\hlkwd{grain}\hlstd{( dG,} \hlkwc{data}\hlstd{=dat ))}
\hlstd{gr.uG} \hlkwb{<-} \hlkwd{compile}\hlstd{(}\hlkwd{grain}\hlstd{( uG,} \hlkwc{data}\hlstd{=dat ))}
\end{alltt}
\end{kframe}
\end{knitrout}

However, when there are zeros in the table, care must be taken.

\subsection{Extracting information from tables}
\label{sec:extr-inform-from}

In the process of creating networks, conditional probability tables
are extracted when the graph is a dag and clique potentials are
extracted when the graph is a chordal (i.e.\ triangulated) undirected
graph. This takes place as follows (internally):

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{extractCPT}\hlstd{(dat, dG) |>} \hlkwd{c}\hlstd{()} \hlcom{## FIXME: Printing problem}
\end{alltt}
\begin{verbatim}
## $A
##       B
## A           lev1 lev2
##   lev1 0.3333333  0.3
##   lev2 0.6666667  0.7
## 
## $B
##       C
## B      lev1  lev2
##   lev1    0 0.375
##   lev2    1 0.625
## 
## $C
## C
##      lev1      lev2 
## 0.3846154 0.6153846
\end{verbatim}
\begin{alltt}
\hlkwd{extractPOT}\hlstd{(dat, uG) |>} \hlkwd{c}\hlstd{()} \hlcom{## FIXME: Printing problem}
\end{alltt}
\begin{verbatim}
## [[1]]
##       A
## B            lev1      lev2
##   lev1 0.07692308 0.1538462
##   lev2 0.23076923 0.5384615
## 
## [[2]]
##       B
## C      lev1 lev2
##   lev1    0  0.5
##   lev2    1  0.5
\end{verbatim}
\end{kframe}
\end{knitrout}

The conditional probability table $P(A|B)$ contains \code{NaN}s
because
\begin{displaymath}
  P(A|B=B1)=\frac{n(A,B=B1)}{\sum_A n(A,B=B1)} = \frac{0}{0} = \mbox{NaN}
\end{displaymath}

For this reason the network \code{gr.dG} above will fail to compile
whereas \code{gr.uG} will work, but it may not give the expected results.

\subsection{Using smooth}
\label{sec:using-smooth}

To illustrate what goes on, we can extract the distributions from data
as follows:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{p.A_B} \hlkwb{<-} \hlkwd{tabDiv}\hlstd{(dat,} \hlkwd{tabMarg}\hlstd{(dat,} \hlstr{"B"}\hlstd{))} \hlcom{## p(A|B)}
\hlstd{p.B}   \hlkwb{<-} \hlkwd{tabMarg}\hlstd{(dat,} \hlstr{"B"}\hlstd{)} \hlopt{/} \hlkwd{sum}\hlstd{(dat)}   \hlcom{## p(B)}
\hlstd{p.AB2} \hlkwb{<-} \hlkwd{tabMult}\hlstd{(p.A_B, p.B)}            \hlcom{## P(AB)}
\end{alltt}
\end{kframe}
\end{knitrout}

However, the result is slightly misleading because \code{tabDiv}
sets $0/0=0$.
In \grain\ there is a \code{smooth} argument that will add a small
number to the cell entries before extracting tables, i.e.
\begin{displaymath}
  P(A|B=B1)=\frac{n(A,B=B1)+\epsilon}{\sum_A ( n(A,B=B1) + \epsilon) }
  = \frac{\epsilon}{2\epsilon} = 0.5
\end{displaymath}
and
\begin{displaymath}
  P(B)= \frac{\sum_A (n(A,B)+\epsilon)}{\sum_{AB} (n(A,B)+\epsilon)}
\end{displaymath}

We can mimic this as follows:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{e} \hlkwb{<-} \hlnum{1e-2}
\hlstd{(dat.e} \hlkwb{<-} \hlstd{dat} \hlopt{+} \hlstd{e)}
\end{alltt}
\begin{verbatim}
## , , C = lev1
## 
##       B
## A      lev1 lev2
##   lev1 0.01 2.01
##   lev2 0.01 3.01
## 
## , , C = lev2
## 
##       B
## A      lev1 lev2
##   lev1 1.01 1.01
##   lev2 2.01 4.01
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{pe.A_B} \hlkwb{<-} \hlkwd{tabDiv}\hlstd{(dat.e,} \hlkwd{tabMarg}\hlstd{(dat.e,} \hlstr{"B"}\hlstd{))}
\hlstd{pe.B}   \hlkwb{<-} \hlkwd{tabMarg}\hlstd{(dat.e,} \hlstr{"B"}\hlstd{)} \hlopt{/} \hlkwd{sum}\hlstd{(dat.e)}
\hlstd{pe.AB}  \hlkwb{<-} \hlkwd{tabMult}\hlstd{(pe.A_B, pe.B)}
\end{alltt}
\end{kframe}
\end{knitrout}

However this resulting joint distribution is different from what is
obtained from the adjusted table itself
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{dat2.e} \hlkwb{<-} \hlstd{dat.e} \hlopt{/} \hlkwd{sum}\hlstd{(dat.e)}
\end{alltt}
\end{kframe}
\end{knitrout}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{(dat2.e} \hlopt{-} \hlstd{pe.AB)  |>} \hlkwd{ftable}\hlstd{()}
\end{alltt}
\begin{verbatim}
##           C       lev1       lev2
## A    B                           
## lev1 lev1    0.0000000 -0.0764526
##      lev2    0.0764526  0.0000000
## lev2 lev1    0.0000000 -0.0764526
##      lev2    0.0764526  0.0000000
\end{verbatim}
\end{kframe}
\end{knitrout}
This difference appears in the \grbn\ networks.

\subsection{Extracting tables}
\label{sec:extracting-tables}

One can do
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{gr.dG} \hlkwb{<-} \hlkwd{grain}\hlstd{(dG,} \hlkwc{data}\hlstd{=dat,} \hlkwc{smooth}\hlstd{=e)}
\end{alltt}
\end{kframe}
\end{knitrout}

which (internally) corresponds to
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{extractCPT}\hlstd{(dat, dG,} \hlkwc{smooth}\hlstd{=e)  |>} \hlkwd{c}\hlstd{()}
\end{alltt}
\begin{verbatim}
## $A
##       B
## A           lev1      lev2
##   lev1 0.3344371 0.3003992
##   lev2 0.6655629 0.6996008
## 
## $B
##       C
## B             lev1      lev2
##   lev1 0.001992032 0.3753117
##   lev2 0.998007968 0.6246883
## 
## $C
## C
##      lev1      lev2 
## 0.3847926 0.6152074
\end{verbatim}
\end{kframe}
\end{knitrout}

We get
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{querygrain}\hlstd{(gr.dG,} \hlkwc{exclude}\hlstd{=}\hlnum{FALSE}\hlstd{,} \hlkwc{simplify}\hlstd{=}\hlnum{TRUE}\hlstd{)}
\end{alltt}
\begin{verbatim}
##        lev1      lev2
## A 0.3082845 0.6917155
## B 0.2316611 0.7683389
## C 0.3847926 0.6152074
\end{verbatim}
\begin{alltt}
\hlkwd{querygrain}\hlstd{(gr.uG,} \hlkwc{exclude}\hlstd{=}\hlnum{FALSE}\hlstd{,} \hlkwc{simplify}\hlstd{=}\hlnum{TRUE}\hlstd{)}
\end{alltt}
\begin{verbatim}
##        lev1      lev2
## B 0.2307692 0.7692308
## A 0.3076923 0.6923077
## C 0.3846154 0.6153846
\end{verbatim}
\end{kframe}
\end{knitrout}

However, if we condition on \code{B=lev1} we get:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{querygrain}\hlstd{(gr.dG,} \hlkwc{evidence}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{B}\hlstd{=}\hlstr{"lev1"}\hlstd{),} \hlkwc{exclude}\hlstd{=}\hlnum{FALSE}\hlstd{,} \hlkwc{simplify}\hlstd{=}\hlnum{TRUE}\hlstd{)}
\end{alltt}
\begin{verbatim}
##          lev1      lev2
## A 0.334437086 0.6655629
## B 1.000000000 0.0000000
## C 0.003308796 0.9966912
\end{verbatim}
\begin{alltt}
\hlkwd{querygrain}\hlstd{(gr.uG,} \hlkwc{evidence}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{B}\hlstd{=}\hlstr{"lev1"}\hlstd{),} \hlkwc{exclude}\hlstd{=}\hlnum{FALSE}\hlstd{,} \hlkwc{simplify}\hlstd{=}\hlnum{TRUE}\hlstd{)}
\end{alltt}
\begin{verbatim}
##        lev1      lev2
## B 1.0000000 0.0000000
## A 0.3333333 0.6666667
## C 0.0000000 1.0000000
\end{verbatim}
\end{kframe}
\end{knitrout}

so the ``problem'' with zero entries shows up in a different
place. However, the answer is not necessarily wrong; the answer simply
states that $P(A|B=lev1)$ is undefined.
To ``remedy'' we can use the \code{smooth} argument:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{gr.uG} \hlkwb{<-} \hlkwd{grain}\hlstd{(uG,} \hlkwc{data}\hlstd{=dat,} \hlkwc{smooth}\hlstd{=e)}
\end{alltt}
\end{kframe}
\end{knitrout}
which (internally) corresponds to
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{extractPOT}\hlstd{(dat, uG,} \hlkwc{smooth}\hlstd{=e) |>} \hlkwd{c}\hlstd{()}
\end{alltt}
\begin{verbatim}
## [[1]]
##       A
## B            lev1      lev2
##   lev1 0.07745399 0.1541411
##   lev2 0.23082822 0.5375767
## 
## [[2]]
##       B
## C             lev1 lev2
##   lev1 0.003311258  0.5
##   lev2 0.996688742  0.5
\end{verbatim}
\end{kframe}
\end{knitrout}

Notice that the results are not exactly identical:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{querygrain}\hlstd{(gr.dG,} \hlkwc{exclude}\hlstd{=}\hlnum{FALSE}\hlstd{,} \hlkwc{simplify}\hlstd{=}\hlnum{TRUE}\hlstd{)}
\end{alltt}
\begin{verbatim}
##        lev1      lev2
## A 0.3082845 0.6917155
## B 0.2316611 0.7683389
## C 0.3847926 0.6152074
\end{verbatim}
\begin{alltt}
\hlkwd{querygrain}\hlstd{(gr.uG,} \hlkwc{exclude}\hlstd{=}\hlnum{FALSE}\hlstd{,} \hlkwc{simplify}\hlstd{=}\hlnum{TRUE}\hlstd{)}
\end{alltt}
\begin{verbatim}
##        lev1      lev2
## B 0.2315951 0.7684049
## A 0.3082822 0.6917178
## C 0.3849693 0.6150307
\end{verbatim}
\end{kframe}
\end{knitrout}


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{querygrain}\hlstd{(gr.dG,} \hlkwc{evidence}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{B}\hlstd{=}\hlstr{"lev1"}\hlstd{),} \hlkwc{exclude}\hlstd{=}\hlnum{FALSE}\hlstd{,} \hlkwc{simplify}\hlstd{=}\hlnum{TRUE}\hlstd{)}
\end{alltt}
\begin{verbatim}
##          lev1      lev2
## A 0.334437086 0.6655629
## B 1.000000000 0.0000000
## C 0.003308796 0.9966912
\end{verbatim}
\begin{alltt}
\hlkwd{querygrain}\hlstd{(gr.uG,} \hlkwc{evidence}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{B}\hlstd{=}\hlstr{"lev1"}\hlstd{),} \hlkwc{exclude}\hlstd{=}\hlnum{FALSE}\hlstd{,} \hlkwc{simplify}\hlstd{=}\hlnum{TRUE}\hlstd{)}
\end{alltt}
\begin{verbatim}
##          lev1      lev2
## B 1.000000000 0.0000000
## A 0.334437086 0.6655629
## C 0.003311258 0.9966887
\end{verbatim}
\end{kframe}
\end{knitrout}




\subsection{Brute force computations and why they fail}
\label{sec:brute-force-comp}


The \grbn\ package makes computations as those outlined above in a
very efficient way; please see the references.  However, it is in this
small example also possible to make the computations directly: We can
construct the joint distribution (an array with $2^8=256$ entries) directly as:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{joint} \hlkwb{<-} \hlkwd{tabListMult}\hlstd{(chest_cpt)}
\hlkwd{dim}\hlstd{(joint)}
\end{alltt}
\begin{verbatim}
## [1] 2 2 2 2 2 2 2 2
\end{verbatim}
\begin{alltt}
\hlstd{joint  |>} \hlkwd{as.data.frame.table}\hlstd{() |>} \hlkwd{head}\hlstd{()}
\end{alltt}
\begin{verbatim}
##   xray lung asia smoke tub dysp bronc either        Freq
## 1  yes  yes  yes   yes yes  yes   yes    yes 0.000013230
## 2   no  yes  yes   yes yes  yes   yes    yes 0.000000270
## 3  yes   no  yes   yes yes  yes   yes    yes 0.000119070
## 4   no   no  yes   yes yes  yes   yes    yes 0.000002430
## 5  yes  yes   no   yes yes  yes   yes    yes 0.000261954
## 6   no  yes   no   yes yes  yes   yes    yes 0.000005346
\end{verbatim}
\end{kframe}
\end{knitrout}

This will clearly fail even moderate size problems: For example, a
model with $80$
nodes each with $10$
levels will give a joint state space with $10^{80}$
states; that is about the number of atoms in the universe. Similarly,
$265$
binary variables will result in a joint state space of about the same
size. Yet, \grbn\ has been used succesfully in models with tens of
thousand variables.  The ``trick'' in \grbn\ is to make all
computations without ever forming the joint distribution. 

However, we
can do all the computations by brute force methods as we will
illustrate here:

Marginal distributions are
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{tabMarg}\hlstd{(joint,} \hlstr{"lung"}\hlstd{)}
\end{alltt}
\begin{verbatim}
## lung
##   yes    no 
## 0.055 0.945
\end{verbatim}
\begin{alltt}
\hlkwd{tabMarg}\hlstd{(joint,} \hlstr{"bronc"}\hlstd{)}
\end{alltt}
\begin{verbatim}
## bronc
##  yes   no 
## 0.45 0.55
\end{verbatim}
\end{kframe}
\end{knitrout}

Conditioning on evidence can be done in different ways: The
conditional density is a $6$--way slice of the original $8$--way joint
distribution:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{ev} \hlkwb{<-} \hlkwd{list}\hlstd{(}\hlkwc{asia}\hlstd{=}\hlstr{"yes"}\hlstd{,} \hlkwc{dysp}\hlstd{=}\hlstr{"yes"}\hlstd{)}
\hlstd{cond1} \hlkwb{<-} \hlkwd{tabSlice}\hlstd{(joint,} \hlkwc{slice}\hlstd{=ev)}
\hlstd{cond1} \hlkwb{<-} \hlstd{cond1} \hlopt{/} \hlkwd{sum}\hlstd{(cond1)}
\hlkwd{dim}\hlstd{(cond1)}
\end{alltt}
\begin{verbatim}
## [1] 2 2 2 2 2 2
\end{verbatim}
\begin{alltt}
\hlkwd{tabMarg}\hlstd{(cond1,} \hlstr{"lung"}\hlstd{)}
\end{alltt}
\begin{verbatim}
## lung
##        yes         no 
## 0.09952515 0.90047485
\end{verbatim}
\begin{alltt}
\hlkwd{tabMarg}\hlstd{(cond1,} \hlstr{"bronc"}\hlstd{)}
\end{alltt}
\begin{verbatim}
## bronc
##       yes        no 
## 0.8114021 0.1885979
\end{verbatim}
\end{kframe}
\end{knitrout}

Alternatively, multiply all entries not consistent by zero and all other entries by one and then marginalize:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{cond2} \hlkwb{<-} \hlkwd{tabSliceMult}\hlstd{(joint,} \hlkwc{slice}\hlstd{=ev)}
\hlstd{cond2} \hlkwb{<-} \hlstd{cond2} \hlopt{/} \hlkwd{sum}\hlstd{(cond2)}
\hlkwd{dim}\hlstd{(cond2)}
\end{alltt}
\begin{verbatim}
## [1] 2 2 2 2 2 2 2 2
\end{verbatim}
\begin{alltt}
\hlkwd{tabMarg}\hlstd{(cond2,} \hlstr{"lung"}\hlstd{)}
\end{alltt}
\begin{verbatim}
## lung
##        yes         no 
## 0.09952515 0.90047485
\end{verbatim}
\begin{alltt}
\hlkwd{tabMarg}\hlstd{(cond2,} \hlstr{"bronc"}\hlstd{)}
\end{alltt}
\begin{verbatim}
## bronc
##       yes        no 
## 0.8114021 0.1885979
\end{verbatim}
\end{kframe}
\end{knitrout}


\bibliography{grain}

\end{document}



% << >>= 
% f1 <- function(){
%     cond1 <- ar_slice(joint, slice=ev)
%     cond1 <- cond1 / sum(cond1)
%     dim(cond1)
%     tabMarg(cond1, "lung")    
% }
% f2 <- function(){
%     cond2 <- ar_slice_mult(joint, slice=ev)
%     cond2 <- cond2 / sum(cond2)
%     dim(cond2)
%     tabMarg(cond2, "lung")    
% }
% f1()
% f2()
% querygrain(chest_bn, nodes="lung", evidence=ev)
% chest_bn1 <- propagate(chest_bn)
% if (require(microbenchmark)){
%     microbenchmark(f1(), f2(),
%                    f3=querygrain(chest_bn, nodes="lung", evidence=ev),
%                    f4=querygrain(chest_bn, nodes="lung", evidence=ev)                   
%                    )                   
% }
% @


%%\SweaveInput{Rmarkup.STY}
%% ------------------------
%% \definecolor{darkred}{rgb}{.7,0,0}
%% \definecolor{midnightblue}{rgb}{0.098,0.098,0.439}
%% 
%% \DefineVerbatimEnvironment{Sinput}{Verbatim}{
%%   fontfamily=tt,
%%   %%fontseries=b,
%%   %% xleftmargin=2em,
%%   formatcom={\color{midnightblue}}
%% }
%% \DefineVerbatimEnvironment{Soutput}{Verbatim}{
%%   fontfamily=tt,
%%   %%fontseries=b,
%%   %% xleftmargin=2em,
%%   formatcom={\color{darkred}}
%% }
%% \DefineVerbatimEnvironment{Scode}{Verbatim}{
%%   fontfamily=tt,
%%   %%fontseries=b,
%%   %% xleftmargin=2em,
%%   formatcom={\color{blue}}
%% }
%% 
%% \fvset{listparameters={\setlength{\topsep}{-2pt}}}
%% \renewenvironment{Schunk}{\linespread{.90}}{}
%% %% ------------------------
%% 




% We can look closer into this zero--probability issue. Because the node
% \code{either} is logical, half of the configurations will have zero probability:

% <<>>=
% tt <- querygrain(chest_bn, type="joint")
% sum(tt == 0) / length(tt)
% @ %def

% In particular the configuration above has zero probability
% <<>>=
% sum(ar_slice(tt, list(either="no", tub="yes")))
% @ %def


